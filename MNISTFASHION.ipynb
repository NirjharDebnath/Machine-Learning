{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NirjharDebnath/Machine-Learning/blob/main/MNISTFASHION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiyPjA26RBa_",
        "outputId": "8262dc4a-182e-411a-9a0d-f4dc5a7feafd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.0+cu124\n",
            "0.20.0+cu124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nirjhar/Python Codes/Machine Learning/torchenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from timeit import default_timer as timer\n",
        "from helper_fn import accuracy_fn\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1q8h4raXRBbB",
        "outputId": "51895af8-055f-4ad5-e251-bb12db220f07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSIHPbu7RBbB"
      },
      "outputs": [],
      "source": [
        "train_data = torchvision.datasets.FashionMNIST(root=\"Data\", download=True, train=True, transform=transforms.ToTensor(),target_transform=None)\n",
        "test_data = torchvision.datasets.FashionMNIST(root=\"Data\", download=True, train=False, transform=transforms.ToTensor(),target_transform=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njbgKYooRBbB",
        "outputId": "d2ae1556-48d4-4fa5-d0bc-f2945e3bbb1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['T-shirt/top',\n",
              " 'Trouser',\n",
              " 'Pullover',\n",
              " 'Dress',\n",
              " 'Coat',\n",
              " 'Sandal',\n",
              " 'Shirt',\n",
              " 'Sneaker',\n",
              " 'Bag',\n",
              " 'Ankle boot']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx\n",
        "class_names = train_data.classes\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxRKflngRBbB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNspjx-5RBbB",
        "outputId": "d7e7db22-b87b-4d24-b21d-21b0e2b8a552"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXk1dwNkRBbC"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IxldH4oRBbC"
      },
      "outputs": [],
      "source": [
        "class ModelCNN(nn.Module):\n",
        "    def __init__(self, input_shape, output_shape, hidden_units):\n",
        "        super().__init__()\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      padding=1,\n",
        "                      stride=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      padding=1,\n",
        "                      stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      padding=1,\n",
        "                      stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=hidden_units*7*7,\n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.convblock1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.convblock2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.classifier(x)\n",
        "        return(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SO-90UX8RBbC"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model = ModelCNN(input_shape=1,\n",
        "                 output_shape=len(class_names),\n",
        "                 hidden_units=10).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDgPw5IeRBbC"
      },
      "outputs": [],
      "source": [
        "lossfn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlmaXCpIRBbC",
        "outputId": "3041eec2-c832-4866-dee3-c827458d57d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image = torch.randn(size=(1,28,28)).to(device)\n",
        "out = model(image.unsqueeze(dim=0))\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9LEHRW9RBbD"
      },
      "outputs": [],
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "    train_loss, train_acc = 0, 0\n",
        "    model.to(device)\n",
        "\n",
        "    for batch, (X, y) in enumerate(data_loader):\n",
        "        # Send data to GPU\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss\n",
        "        train_acc += accuracy_fn(y_true=y,\n",
        "                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate loss and accuracy per epoch and print out what's happening\n",
        "    train_loss /= len(data_loader)\n",
        "    train_acc /= len(data_loader)\n",
        "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
        "\n",
        "def test_step(data_loader: torch.utils.data.DataLoader,\n",
        "              model: torch.nn.Module,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model.to(device)\n",
        "    model.eval() # put model in eval mode\n",
        "    # Turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "        for X, y in data_loader:\n",
        "            # Send data to GPU\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred = model(X)\n",
        "\n",
        "            # 2. Calculate loss and accuracy\n",
        "            test_loss += loss_fn(test_pred, y)\n",
        "            test_acc += accuracy_fn(y_true=y,\n",
        "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
        "            )\n",
        "\n",
        "        # Adjust metrics and print out\n",
        "        test_loss /= len(data_loader)\n",
        "        test_acc /= len(data_loader)\n",
        "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQDH5FpFRBbD",
        "outputId": "4c9d35b0-0445-4c34-bd2f-cc07d5a5accc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "---------\n",
            "Train loss: 0.63393 | Train accuracy: 77.39%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 1/4 [00:07<00:21,  7.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.40455 | Test accuracy: 85.51%\n",
            "\n",
            "Epoch: 1\n",
            "---------\n",
            "Train loss: 0.38117 | Train accuracy: 86.17%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 2/4 [00:14<00:14,  7.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.37164 | Test accuracy: 86.55%\n",
            "\n",
            "Epoch: 2\n",
            "---------\n",
            "Train loss: 0.34345 | Train accuracy: 87.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 3/4 [00:20<00:06,  6.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.33835 | Test accuracy: 88.08%\n",
            "\n",
            "Epoch: 3\n",
            "---------\n",
            "Train loss: 0.31915 | Train accuracy: 88.47%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:28<00:00,  7.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.33208 | Test accuracy: 88.16%\n",
            "\n",
            "Total time taken on cuda : 28.040696779999053\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Measure time\n",
        "from timeit import default_timer as timer\n",
        "timeron = timer()\n",
        "\n",
        "# Train and test model\n",
        "EPOCHS = 4\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    print(f\"Epoch: {epoch}\\n---------\")\n",
        "    train_step(data_loader=train_dataloader,\n",
        "        model=model,\n",
        "        loss_fn=lossfn,\n",
        "        optimizer=optimizer,\n",
        "        accuracy_fn=accuracy_fn,\n",
        "        device=device\n",
        "    )\n",
        "    test_step(data_loader=test_dataloader,\n",
        "        model=model,\n",
        "        loss_fn=lossfn,\n",
        "        accuracy_fn=accuracy_fn,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "timeroff = timer()\n",
        "print(f\"Total time taken on {device} : {timeroff-timeron}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8CH_-PsRBbD",
        "outputId": "9f9e6ddb-95fb-40cb-9ff4-97750880cf64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model_name': 'ModelCNN', 'model_loss': 0.33208173513412476, 'model_acc': 88.15894568690096}\n"
          ]
        }
      ],
      "source": [
        "from helpers import eval_model\n",
        "# print(device)\n",
        "modelresults = eval_model(model=model,\n",
        "                          data_loader=test_dataloader,\n",
        "                          loss_fn=lossfn,\n",
        "                          accuracy_fn=accuracy_fn,\n",
        "                          device=device)\n",
        "print(modelresults)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeRXGOeYRBbD",
        "outputId": "265832e8-ae8d-4f8c-8de7-3a920655d9f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method Module._save_to_state_dict of ModelCNN(\n",
              "  (convblock1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (convblock2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
              "  )\n",
              ")>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model._save_to_state_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9q_5ShFRBbD",
        "outputId": "0e0fdb11-ac07-46c4-8cc7-29c72e1bd5f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image tensor shape: torch.Size([1, 28, 28])\n",
            "Image tensor data type: torch.float32\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "def image_to_tensor(image_path):\n",
        "    \"\"\"\n",
        "    Converts a saved image to a PyTorch tensor.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the image file.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The image as a PyTorch tensor.\n",
        "                      Returns None if there's an error loading or processing the image.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Open the image using PIL\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # 2. Define transformations (optional, but highly recommended)\n",
        "        #    - Convert to RGB (if the image is grayscale or has an alpha channel)\n",
        "        #    - Resize to a consistent size (if needed for your model)\n",
        "        #    - Convert to tensor\n",
        "        #    - Normalize pixel values (usually between 0 and 1 or -1 and 1, depending on the model)\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),  # Convert to tensor\n",
        "            transforms.Resize((28, 28)), # Resize to a common size (adjust as needed) If removed, keep transforms.CenterCrop below\n",
        "            # transforms.CenterCrop(28), # Center crop to the specified size\n",
        "            # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats (adjust if using a different dataset)\n",
        "        ])\n",
        "\n",
        "\n",
        "\n",
        "        # 3. Apply the transformations\n",
        "        tensor = transform(image)\n",
        "\n",
        "\n",
        "        return tensor\n",
        "\n",
        "    except (FileNotFoundError, OSError, ValueError) as e:  # Catch potential errors like file not found, or image format issues\n",
        "        print(f\"Error loading or processing image: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "image_path = \"/home/nirjhar/Python Codes/Machine Learning/shoe2.png\" # Replace with the actual path to your image\n",
        "image_tensor = image_to_tensor(image_path)\n",
        "\n",
        "if image_tensor is not None:\n",
        "    print(f\"Image tensor shape: {image_tensor.shape}\")\n",
        "    print(f\"Image tensor data type: {image_tensor.dtype}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYWyCjhcRBbD"
      },
      "outputs": [],
      "source": [
        "image_tensor = image_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXNSGL1kRBbE",
        "outputId": "9b9eaf7a-2d5d-4138-95fc-e9f346b797da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([9], device='cuda:0')"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output = model(image_tensor.unsqueeze(dim=0))\n",
        "output.argmax(dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdlGkRGJRBbE",
        "outputId": "a09080dd-f28c-4c62-9c53-c2395c562840"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'T-shirt/top': 0,\n",
              " 'Trouser': 1,\n",
              " 'Pullover': 2,\n",
              " 'Dress': 3,\n",
              " 'Coat': 4,\n",
              " 'Sandal': 5,\n",
              " 'Shirt': 6,\n",
              " 'Sneaker': 7,\n",
              " 'Bag': 8,\n",
              " 'Ankle boot': 9}"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oYVpWedRBbE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torchenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}